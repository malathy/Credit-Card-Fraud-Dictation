{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Card Fraud Detection\n",
    "\n",
    "In this project you will predict fraudulent credit card transactions with the help of Machine learning models. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observe the different feature type present in the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking ROws and Columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set has 284807 rows and 31 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Checking Data set info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  All columns are numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking NULL Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IT is good that no null values in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will observe the distribution of our classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal_share : 99.82725143693798\n",
      "Fraud_share : 0.1727485630620034\n"
     ]
    }
   ],
   "source": [
    "classes=df['Class'].value_counts()\n",
    "normal_share=classes[0]/df['Class'].count()*100\n",
    "fraud_share=classes[1]/df['Class'].count()*100\n",
    "print(\"Normal_share :\",normal_share);\n",
    "print(\"Fraud_share :\",fraud_share);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From Above code we can understand that  99.82% in the data set contains no fraud data that is normal share.\n",
    "##### Only 0.17% in the data set is treated as fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Bar plot for the number and percentage of fraudulent vs non-fraudulent')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\n",
    "import seaborn as sns\n",
    "Colours=['g','r']\n",
    "sns.countplot('Class', data=df, palette=Colours)\n",
    "plt.title('Bar plot for the number and percentage of fraudulent vs non-fraudulent', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0  indicates  Non-Fraudulent\n",
    "#### 1 indicates Fraudulent\n",
    "#### So we can see that data set is highly imbalanced between Non-Fraudulent and Fraudulent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with time\n",
    "\n",
    "plt.scatter(df.Time,df.Class)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot to observe the distribution of classes with Amount\n",
    "plt.scatter(df.Amount,df.Class)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnecessary columns\n",
    "Here 28 columns are Transformed using PCA for security reasons.So it is difficult to make assumption about unnecessary columns.we decided that do not drop the columns and feed all of them in to model and let the model decide  which feature should exists or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"Class\",axis=1)\n",
    "y=df.Class #class variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 4, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213605, 30)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print shapes of train and test sets\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71202, 30)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shapes of train and test sets\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213605,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shapes of train and test sets\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71202,)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print shapes of train and test sets\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preserve X_test & y_test to evaluate on the test data once you build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "369\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y))\n",
    "print(np.sum(y_train))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the distribution of a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.28880051, 2.1569084 , 5.29233445, ..., 5.29465008, 5.29465136,\n",
       "       5.29463801])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking Skewness of all columns.\n",
    "#For normally distributed data, the skewness should be about zero\n",
    "#a skewness value greater than zero means that there is more weight in the right tail of the distribution. \n",
    "from scipy.stats import skew\n",
    "skew(df, axis=1, bias=True, nan_policy='propagate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset to see the skewness\n",
    "df.plot.hist(alpha=0.5, bins=15, grid=True, legend=None)  # Pandas helper function to plot a hist. Uses matplotlib under the hood.\n",
    "plt.xlabel(\"Feature value\")\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Skewness exists in right tail ..That means more weight in the right tail of the distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there is skewness present in the distribution use:\n",
    "- <b>Power Transformer</b> package present in the <b>preprocessing library provided by sklearn</b> to make distribution more gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36368005, -1.09405765, -0.77707764, ...,  0.54867031,\n",
       "         0.46696081,  1.0871737 ],\n",
       "       [ 1.52598286, -0.03665817,  0.69930236, ...,  0.4714118 ,\n",
       "         0.95915142, -0.19107802],\n",
       "       [ 0.40747956, -0.56813152, -0.31412177, ...,  0.01983333,\n",
       "         0.15313608, -0.19606017],\n",
       "       ...,\n",
       "       [ 1.38376912, -1.14390352, -1.67191402, ...,  0.04860193,\n",
       "         0.65175698,  0.7673976 ],\n",
       "       [ 0.27178728, -0.73662436,  0.19813169, ..., -0.45317086,\n",
       "        -0.55802389, -1.24032163],\n",
       "       [-0.98584285, -0.83269512, -0.11415457, ..., -0.4324947 ,\n",
       "         0.26444543,  1.49068557]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Apply : preprocessing.PowerTransformer(copy=False) to fit & transform the train & test data\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "#preprocessing.PowerTransformer(df,method='yeo-johnson', standardize=True, copy=False)\n",
    "pt = PowerTransformer(copy=False)\n",
    "X_train=pt.fit_transform(X_train)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33122625,  1.20181348, -0.5891964 , ...,  0.21249609,\n",
       "        -0.09285891, -1.53780112],\n",
       "       [ 1.45098664, -1.13957847,  0.42425898, ...,  0.45705365,\n",
       "         0.16658161,  0.34816964],\n",
       "       [ 1.12260505, -0.59420318, -0.18246195, ..., -0.32274256,\n",
       "        -0.13523149,  1.09664933],\n",
       "       ...,\n",
       "       [ 0.8781395 , -1.10305634, -0.66196251, ...,  0.31861597,\n",
       "         0.51357019,  1.72093891],\n",
       "       [-0.71298999,  0.46644844, -0.91846466, ..., -0.13808763,\n",
       "         0.04549527,  1.39352142],\n",
       "       [ 0.65404676,  1.50410215, -0.0625646 , ..., -0.24236853,\n",
       "        -0.23296202, -0.12542517]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test = pt.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the histogram of a variable from the dataset again to see the result \n",
    "df1 = pd.DataFrame(X_train)\n",
    "df1.plot.hist(alpha=0.5, bins=15, grid=True, legend=None)  # Pandas helper function to plot a hist. Uses matplotlib under the hood.\n",
    "\n",
    "# Plot a line of the fitted distribution over the top\n",
    "\n",
    "plt.xlabel(\"Feature value\")\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The Histogram looks like good and more gaussian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24496426, -1.99658302],\n",
       "       [-0.34247454, -1.99658302],\n",
       "       [ 1.16068593, -1.99656197],\n",
       "       ...,\n",
       "       [-0.0818393 ,  1.6419735 ],\n",
       "       [-0.31324853,  1.6419735 ],\n",
       "       [ 0.51435531,  1.64205773]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler= StandardScaler()\n",
    "scaler.fit_transform(df[['Amount','Time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building on the imbalanced dataset\n",
    "- Build different models on the imbalanced dataset and see the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-04 1.45634848e-04 2.12095089e-04 3.08884360e-04\n",
      " 4.49843267e-04 6.55128557e-04 9.54095476e-04 1.38949549e-03\n",
      " 2.02358965e-03 2.94705170e-03 4.29193426e-03 6.25055193e-03\n",
      " 9.10298178e-03 1.32571137e-02 1.93069773e-02 2.81176870e-02\n",
      " 4.09491506e-02 5.96362332e-02 8.68511374e-02 1.26485522e-01\n",
      " 1.84206997e-01 2.68269580e-01 3.90693994e-01 5.68986603e-01\n",
      " 8.28642773e-01 1.20679264e+00 1.75751062e+00 2.55954792e+00\n",
      " 3.72759372e+00 5.42867544e+00 7.90604321e+00 1.15139540e+01\n",
      " 1.67683294e+01 2.44205309e+01 3.55648031e+01 5.17947468e+01\n",
      " 7.54312006e+01 1.09854114e+02 1.59985872e+02 2.32995181e+02\n",
      " 3.39322177e+02 4.94171336e+02 7.19685673e+02 1.04811313e+03\n",
      " 1.52641797e+03 2.22299648e+03 3.23745754e+03 4.71486636e+03\n",
      " 6.86648845e+03 1.00000000e+04]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model #import the package\n",
    "\n",
    "num_C =  np.logspace(-4, 4, 50)  #--> list of values\n",
    "cv_num =num_C   #--> list of values\n",
    "print(num_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "#perform cross validation.\n",
    "#here we are using StratifiedKFold validation\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "x=X_train\n",
    "y=y_train\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(x,y)\n",
    "print(skf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 42719  42720  42721 ... 213602 213603 213604] TEST: [    0     1     2 ... 42967 44006 44559]\n",
      "TRAIN: [     0      1      2 ... 213602 213603 213604] TEST: [42719 42720 42721 ... 88287 88494 88505]\n",
      "TRAIN: [     0      1      2 ... 213602 213603 213604] TEST: [ 85438  85439  85440 ... 128164 128165 128166]\n",
      "TRAIN: [     0      1      2 ... 213602 213603 213604] TEST: [126928 127080 127687 ... 171746 172150 172213]\n",
      "TRAIN: [     0      1      2 ... 171746 172150 172213] TEST: [170880 170881 170882 ... 213602 213603 213604]\n"
     ]
    }
   ],
   "source": [
    "#perfom cross validation on the X_train & y_train\n",
    "for train_index, test_index in skf.split(x,y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_cv, X_test_cv= x[train_index], x[test_index]\n",
    "    y_train_cv, y_test_cv = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyper Parameter Tunning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameter Tunning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "logistic = linear_model.LogisticRegression()\n",
    "steps = [\n",
    "        \n",
    "         (\"logistic\",logistic )\n",
    "        ]\n",
    "logistic_pipeline = Pipeline(steps)\n",
    "# Create a list of options for the regularization penalty\n",
    "#penalty = ['l1', 'l2']\n",
    "\n",
    "params = { 'logistic__C': num_C, 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "# create gridsearch object\n",
    "clf = GridSearchCV(estimator=logistic_pipeline, cv=skf, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 10.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('logistic',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='wa...\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         'logistic__penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with best Params\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC:  0.9800766800568095\n",
      "Best hyperparameters:  {'logistic__C': 0.009102981779915217, 'logistic__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", clf.best_score_)\n",
    "print(\"Best hyperparameters: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of test data:    \t 0.98\n"
     ]
    }
   ],
   "source": [
    "# predict  on test data\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# predict  on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "# check area under curve\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC of test data:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_logistic__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.071639</td>\n",
       "      <td>0.105512</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.232585</td>\n",
       "      <td>0.053183</td>\n",
       "      <td>0.034591</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.938569</td>\n",
       "      <td>0.955992</td>\n",
       "      <td>0.923399</td>\n",
       "      <td>0.959528</td>\n",
       "      <td>0.939764</td>\n",
       "      <td>0.943450</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.014032</td>\n",
       "      <td>0.019535</td>\n",
       "      <td>0.021822</td>\n",
       "      <td>0.005566</td>\n",
       "      <td>0.000145635</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00014563484775012445, 'logis...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.367666</td>\n",
       "      <td>0.062342</td>\n",
       "      <td>0.048873</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.000145635</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00014563484775012445, 'logis...</td>\n",
       "      <td>0.949483</td>\n",
       "      <td>0.962790</td>\n",
       "      <td>0.945757</td>\n",
       "      <td>0.967712</td>\n",
       "      <td>0.953045</td>\n",
       "      <td>0.955757</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.150499</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.023615</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.000212095</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00021209508879201905, 'logis...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.527690</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.000212095</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00021209508879201905, 'logis...</td>\n",
       "      <td>0.955810</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>0.962917</td>\n",
       "      <td>0.976736</td>\n",
       "      <td>0.957551</td>\n",
       "      <td>0.964101</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.206593</td>\n",
       "      <td>0.041277</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.000308884</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00030888435964774815, 'logis...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.574906</td>\n",
       "      <td>0.061324</td>\n",
       "      <td>0.044962</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.000308884</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00030888435964774815, 'logis...</td>\n",
       "      <td>0.958557</td>\n",
       "      <td>0.971019</td>\n",
       "      <td>0.971460</td>\n",
       "      <td>0.979753</td>\n",
       "      <td>0.960127</td>\n",
       "      <td>0.968183</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.220359</td>\n",
       "      <td>0.035610</td>\n",
       "      <td>0.021537</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000449843</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0004498432668969444, 'logist...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.498864</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.040789</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.000449843</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0004498432668969444, 'logist...</td>\n",
       "      <td>0.960077</td>\n",
       "      <td>0.973816</td>\n",
       "      <td>0.977599</td>\n",
       "      <td>0.981605</td>\n",
       "      <td>0.962719</td>\n",
       "      <td>0.971163</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.456693</td>\n",
       "      <td>0.047632</td>\n",
       "      <td>0.052384</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.000655129</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0006551285568595509, 'logist...</td>\n",
       "      <td>0.850704</td>\n",
       "      <td>0.831897</td>\n",
       "      <td>0.813248</td>\n",
       "      <td>0.868012</td>\n",
       "      <td>0.881864</td>\n",
       "      <td>0.849145</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.423100</td>\n",
       "      <td>0.017942</td>\n",
       "      <td>0.039721</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.000655129</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0006551285568595509, 'logist...</td>\n",
       "      <td>0.961160</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.983289</td>\n",
       "      <td>0.982896</td>\n",
       "      <td>0.965583</td>\n",
       "      <td>0.973777</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.772538</td>\n",
       "      <td>0.085089</td>\n",
       "      <td>0.055631</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.000954095</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0009540954763499944, 'logist...</td>\n",
       "      <td>0.908338</td>\n",
       "      <td>0.900663</td>\n",
       "      <td>0.855768</td>\n",
       "      <td>0.906539</td>\n",
       "      <td>0.922608</td>\n",
       "      <td>0.898783</td>\n",
       "      <td>0.022684</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.533346</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>0.043671</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.000954095</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0009540954763499944, 'logist...</td>\n",
       "      <td>0.961959</td>\n",
       "      <td>0.977961</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>0.983845</td>\n",
       "      <td>0.967937</td>\n",
       "      <td>0.975810</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.947747</td>\n",
       "      <td>0.032699</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.0013895</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0013894954943731374, 'logist...</td>\n",
       "      <td>0.949418</td>\n",
       "      <td>0.933744</td>\n",
       "      <td>0.922404</td>\n",
       "      <td>0.936225</td>\n",
       "      <td>0.943960</td>\n",
       "      <td>0.937150</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.691256</td>\n",
       "      <td>0.049688</td>\n",
       "      <td>0.056951</td>\n",
       "      <td>0.014409</td>\n",
       "      <td>0.0013895</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0013894954943731374, 'logist...</td>\n",
       "      <td>0.962589</td>\n",
       "      <td>0.979977</td>\n",
       "      <td>0.989629</td>\n",
       "      <td>0.984577</td>\n",
       "      <td>0.969920</td>\n",
       "      <td>0.977338</td>\n",
       "      <td>0.009828</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.124661</td>\n",
       "      <td>0.076735</td>\n",
       "      <td>0.055065</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.00202359</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0020235896477251557, 'logist...</td>\n",
       "      <td>0.950841</td>\n",
       "      <td>0.941975</td>\n",
       "      <td>0.932822</td>\n",
       "      <td>0.943234</td>\n",
       "      <td>0.944597</td>\n",
       "      <td>0.942694</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.805883</td>\n",
       "      <td>0.054001</td>\n",
       "      <td>0.049319</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.00202359</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0020235896477251557, 'logist...</td>\n",
       "      <td>0.963029</td>\n",
       "      <td>0.981739</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.985167</td>\n",
       "      <td>0.971700</td>\n",
       "      <td>0.978530</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.262856</td>\n",
       "      <td>0.079648</td>\n",
       "      <td>0.058365</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.00294705</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0029470517025518097, 'logist...</td>\n",
       "      <td>0.951302</td>\n",
       "      <td>0.952835</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.951472</td>\n",
       "      <td>0.945575</td>\n",
       "      <td>0.948402</td>\n",
       "      <td>0.004535</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.852233</td>\n",
       "      <td>0.094498</td>\n",
       "      <td>0.052022</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>0.00294705</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0029470517025518097, 'logist...</td>\n",
       "      <td>0.963345</td>\n",
       "      <td>0.983053</td>\n",
       "      <td>0.991884</td>\n",
       "      <td>0.985501</td>\n",
       "      <td>0.972871</td>\n",
       "      <td>0.979331</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.615600</td>\n",
       "      <td>0.170004</td>\n",
       "      <td>0.057637</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.00429193</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.004291934260128779, 'logisti...</td>\n",
       "      <td>0.952323</td>\n",
       "      <td>0.965110</td>\n",
       "      <td>0.948437</td>\n",
       "      <td>0.957944</td>\n",
       "      <td>0.949320</td>\n",
       "      <td>0.954627</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.854799</td>\n",
       "      <td>0.189326</td>\n",
       "      <td>0.043596</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.00429193</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.004291934260128779, 'logisti...</td>\n",
       "      <td>0.963539</td>\n",
       "      <td>0.983775</td>\n",
       "      <td>0.992501</td>\n",
       "      <td>0.985553</td>\n",
       "      <td>0.973582</td>\n",
       "      <td>0.979790</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.445283</td>\n",
       "      <td>0.093231</td>\n",
       "      <td>0.058512</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.00625055</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0062505519252739694, 'logist...</td>\n",
       "      <td>0.955290</td>\n",
       "      <td>0.973925</td>\n",
       "      <td>0.962230</td>\n",
       "      <td>0.962736</td>\n",
       "      <td>0.955206</td>\n",
       "      <td>0.961877</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.896493</td>\n",
       "      <td>0.113246</td>\n",
       "      <td>0.047329</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.00625055</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0062505519252739694, 'logist...</td>\n",
       "      <td>0.963544</td>\n",
       "      <td>0.984132</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>0.974108</td>\n",
       "      <td>0.980015</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.557081</td>\n",
       "      <td>0.138595</td>\n",
       "      <td>0.064534</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>0.00910298</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.009102981779915217, 'logisti...</td>\n",
       "      <td>0.957226</td>\n",
       "      <td>0.979475</td>\n",
       "      <td>0.975276</td>\n",
       "      <td>0.965908</td>\n",
       "      <td>0.960735</td>\n",
       "      <td>0.967724</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.023326</td>\n",
       "      <td>0.098391</td>\n",
       "      <td>0.047690</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.00910298</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.009102981779915217, 'logisti...</td>\n",
       "      <td>0.963401</td>\n",
       "      <td>0.984235</td>\n",
       "      <td>0.993284</td>\n",
       "      <td>0.984992</td>\n",
       "      <td>0.974471</td>\n",
       "      <td>0.980077</td>\n",
       "      <td>0.010251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.980109</td>\n",
       "      <td>0.364221</td>\n",
       "      <td>0.060676</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>0.0132571</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.013257113655901081, 'logisti...</td>\n",
       "      <td>0.959774</td>\n",
       "      <td>0.984209</td>\n",
       "      <td>0.985014</td>\n",
       "      <td>0.968174</td>\n",
       "      <td>0.965102</td>\n",
       "      <td>0.972455</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.163761</td>\n",
       "      <td>0.075274</td>\n",
       "      <td>0.042849</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>0.0132571</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.013257113655901081, 'logisti...</td>\n",
       "      <td>0.963141</td>\n",
       "      <td>0.984180</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.984563</td>\n",
       "      <td>0.974642</td>\n",
       "      <td>0.980016</td>\n",
       "      <td>0.010343</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.576520</td>\n",
       "      <td>0.534572</td>\n",
       "      <td>0.059333</td>\n",
       "      <td>0.011734</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.019306977288832496, 'logisti...</td>\n",
       "      <td>0.960940</td>\n",
       "      <td>0.987058</td>\n",
       "      <td>0.989361</td>\n",
       "      <td>0.969851</td>\n",
       "      <td>0.967401</td>\n",
       "      <td>0.974922</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.438750</td>\n",
       "      <td>0.050509</td>\n",
       "      <td>0.047096</td>\n",
       "      <td>0.011073</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.019306977288832496, 'logisti...</td>\n",
       "      <td>0.962889</td>\n",
       "      <td>0.983933</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.984245</td>\n",
       "      <td>0.974688</td>\n",
       "      <td>0.979908</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>9.279097</td>\n",
       "      <td>0.229133</td>\n",
       "      <td>0.075557</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>51.7947</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 51.79474679231202, 'logistic__...</td>\n",
       "      <td>0.960247</td>\n",
       "      <td>0.980411</td>\n",
       "      <td>0.992720</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968819</td>\n",
       "      <td>0.977421</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>4.836229</td>\n",
       "      <td>0.612423</td>\n",
       "      <td>0.058578</td>\n",
       "      <td>0.006996</td>\n",
       "      <td>51.7947</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 51.79474679231202, 'logistic__...</td>\n",
       "      <td>0.960247</td>\n",
       "      <td>0.980410</td>\n",
       "      <td>0.992722</td>\n",
       "      <td>0.984904</td>\n",
       "      <td>0.968828</td>\n",
       "      <td>0.977422</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>9.387592</td>\n",
       "      <td>0.468430</td>\n",
       "      <td>0.064235</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>75.4312</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 75.43120063354607, 'logistic__...</td>\n",
       "      <td>0.960244</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.977418</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4.420925</td>\n",
       "      <td>0.566121</td>\n",
       "      <td>0.050258</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>75.4312</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 75.43120063354607, 'logistic__...</td>\n",
       "      <td>0.960243</td>\n",
       "      <td>0.980406</td>\n",
       "      <td>0.992720</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968825</td>\n",
       "      <td>0.977420</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8.776000</td>\n",
       "      <td>0.554547</td>\n",
       "      <td>0.064933</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>109.854</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 109.85411419875572, 'logistic_...</td>\n",
       "      <td>0.960241</td>\n",
       "      <td>0.980401</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>0.984905</td>\n",
       "      <td>0.968819</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>4.450163</td>\n",
       "      <td>0.542113</td>\n",
       "      <td>0.050644</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>109.854</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 109.85411419875572, 'logistic_...</td>\n",
       "      <td>0.960242</td>\n",
       "      <td>0.980401</td>\n",
       "      <td>0.992718</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968822</td>\n",
       "      <td>0.977418</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9.053994</td>\n",
       "      <td>0.817585</td>\n",
       "      <td>0.062307</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>159.986</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 159.98587196060572, 'logistic_...</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>0.977415</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4.466787</td>\n",
       "      <td>0.531580</td>\n",
       "      <td>0.052414</td>\n",
       "      <td>0.008587</td>\n",
       "      <td>159.986</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 159.98587196060572, 'logistic_...</td>\n",
       "      <td>0.960241</td>\n",
       "      <td>0.980399</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968821</td>\n",
       "      <td>0.977417</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>8.844299</td>\n",
       "      <td>0.499845</td>\n",
       "      <td>0.063322</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>232.995</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 232.99518105153672, 'logistic_...</td>\n",
       "      <td>0.960238</td>\n",
       "      <td>0.980396</td>\n",
       "      <td>0.992717</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>0.977415</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.646488</td>\n",
       "      <td>0.545418</td>\n",
       "      <td>0.050726</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>232.995</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 232.99518105153672, 'logistic_...</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.980397</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968819</td>\n",
       "      <td>0.977416</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8.682425</td>\n",
       "      <td>0.653784</td>\n",
       "      <td>0.062710</td>\n",
       "      <td>0.008311</td>\n",
       "      <td>339.322</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 339.3221771895323, 'logistic__...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980395</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984906</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977414</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4.661795</td>\n",
       "      <td>0.535919</td>\n",
       "      <td>0.051099</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>339.322</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 339.3221771895323, 'logistic__...</td>\n",
       "      <td>0.960237</td>\n",
       "      <td>0.980396</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>0.977415</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.872313</td>\n",
       "      <td>0.839155</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>494.171</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 494.1713361323828, 'logistic__...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977414</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4.577792</td>\n",
       "      <td>0.569329</td>\n",
       "      <td>0.051336</td>\n",
       "      <td>0.003410</td>\n",
       "      <td>494.171</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 494.1713361323828, 'logistic__...</td>\n",
       "      <td>0.960237</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968816</td>\n",
       "      <td>0.977414</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.996001</td>\n",
       "      <td>0.407230</td>\n",
       "      <td>0.065570</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>719.686</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 719.6856730011514, 'logistic__...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>4.713231</td>\n",
       "      <td>0.692720</td>\n",
       "      <td>0.050174</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>719.686</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 719.6856730011514, 'logistic__...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8.752831</td>\n",
       "      <td>0.514746</td>\n",
       "      <td>0.059328</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>1048.11</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 1048.1131341546852, 'logistic_...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4.604247</td>\n",
       "      <td>0.537779</td>\n",
       "      <td>0.049984</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>1048.11</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 1048.1131341546852, 'logistic_...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.906186</td>\n",
       "      <td>0.692940</td>\n",
       "      <td>0.060725</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>1526.42</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 1526.4179671752302, 'logistic_...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>4.635918</td>\n",
       "      <td>0.526963</td>\n",
       "      <td>0.054896</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>1526.42</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 1526.4179671752302, 'logistic_...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9.073654</td>\n",
       "      <td>0.796404</td>\n",
       "      <td>0.068362</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>2223</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 2222.996482526191, 'logistic__...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4.634668</td>\n",
       "      <td>0.575807</td>\n",
       "      <td>0.051607</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>2223</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 2222.996482526191, 'logistic__...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980394</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8.776459</td>\n",
       "      <td>0.120249</td>\n",
       "      <td>0.071803</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>3237.46</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 3237.45754281764, 'logistic__p...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.074585</td>\n",
       "      <td>0.594471</td>\n",
       "      <td>0.053604</td>\n",
       "      <td>0.006146</td>\n",
       "      <td>3237.46</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 3237.45754281764, 'logistic__p...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>8.846090</td>\n",
       "      <td>0.531535</td>\n",
       "      <td>0.060774</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>4714.87</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 4714.8663634573895, 'logistic_...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>0.984908</td>\n",
       "      <td>0.968815</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.568093</td>\n",
       "      <td>0.610452</td>\n",
       "      <td>0.050315</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>4714.87</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 4714.8663634573895, 'logistic_...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9.484884</td>\n",
       "      <td>0.671154</td>\n",
       "      <td>0.072124</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>6866.49</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 6866.488450042998, 'logistic__...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.383757</td>\n",
       "      <td>0.779638</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>6866.49</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 6866.488450042998, 'logistic__...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.583913</td>\n",
       "      <td>0.775053</td>\n",
       "      <td>0.073162</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.960236</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4.397454</td>\n",
       "      <td>1.136542</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.960235</td>\n",
       "      <td>0.980393</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>0.984907</td>\n",
       "      <td>0.968814</td>\n",
       "      <td>0.977413</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.071639      0.105512         0.021902        0.002281   \n",
       "1        1.232585      0.053183         0.034591        0.002722   \n",
       "2        1.014032      0.019535         0.021822        0.005566   \n",
       "3        1.367666      0.062342         0.048873        0.011284   \n",
       "4        1.150499      0.041842         0.023615        0.002678   \n",
       "5        1.527690      0.044906         0.043085        0.007872   \n",
       "6        1.206593      0.041277         0.026985        0.007825   \n",
       "7        1.574906      0.061324         0.044962        0.005213   \n",
       "8        1.220359      0.035610         0.021537        0.001847   \n",
       "9        1.498864      0.014113         0.040789        0.002609   \n",
       "10       1.456693      0.047632         0.052384        0.007006   \n",
       "11       1.423100      0.017942         0.039721        0.003179   \n",
       "12       1.772538      0.085089         0.055631        0.005884   \n",
       "13       1.533346      0.039823         0.043671        0.008600   \n",
       "14       1.947747      0.032699         0.060879        0.005397   \n",
       "15       1.691256      0.049688         0.056951        0.014409   \n",
       "16       2.124661      0.076735         0.055065        0.005783   \n",
       "17       1.805883      0.054001         0.049319        0.006334   \n",
       "18       2.262856      0.079648         0.058365        0.006993   \n",
       "19       1.852233      0.094498         0.052022        0.011607   \n",
       "20       2.615600      0.170004         0.057637        0.003196   \n",
       "21       1.854799      0.189326         0.043596        0.004993   \n",
       "22       2.445283      0.093231         0.058512        0.008320   \n",
       "23       1.896493      0.113246         0.047329        0.006574   \n",
       "24       2.557081      0.138595         0.064534        0.009491   \n",
       "25       2.023326      0.098391         0.047690        0.006165   \n",
       "26       2.980109      0.364221         0.060676        0.007295   \n",
       "27       2.163761      0.075274         0.042849        0.003863   \n",
       "28       3.576520      0.534572         0.059333        0.011734   \n",
       "29       2.438750      0.050509         0.047096        0.011073   \n",
       "..            ...           ...              ...             ...   \n",
       "70       9.279097      0.229133         0.075557        0.010669   \n",
       "71       4.836229      0.612423         0.058578        0.006996   \n",
       "72       9.387592      0.468430         0.064235        0.006841   \n",
       "73       4.420925      0.566121         0.050258        0.005511   \n",
       "74       8.776000      0.554547         0.064933        0.005651   \n",
       "75       4.450163      0.542113         0.050644        0.005414   \n",
       "76       9.053994      0.817585         0.062307        0.008265   \n",
       "77       4.466787      0.531580         0.052414        0.008587   \n",
       "78       8.844299      0.499845         0.063322        0.008976   \n",
       "79       4.646488      0.545418         0.050726        0.007300   \n",
       "80       8.682425      0.653784         0.062710        0.008311   \n",
       "81       4.661795      0.535919         0.051099        0.005121   \n",
       "82       8.872313      0.839155         0.059608        0.010474   \n",
       "83       4.577792      0.569329         0.051336        0.003410   \n",
       "84       8.996001      0.407230         0.065570        0.012860   \n",
       "85       4.713231      0.692720         0.050174        0.007659   \n",
       "86       8.752831      0.514746         0.059328        0.005290   \n",
       "87       4.604247      0.537779         0.049984        0.007548   \n",
       "88       8.906186      0.692940         0.060725        0.002760   \n",
       "89       4.635918      0.526963         0.054896        0.010181   \n",
       "90       9.073654      0.796404         0.068362        0.005289   \n",
       "91       4.634668      0.575807         0.051607        0.004153   \n",
       "92       8.776459      0.120249         0.071803        0.013610   \n",
       "93       5.074585      0.594471         0.053604        0.006146   \n",
       "94       8.846090      0.531535         0.060774        0.007783   \n",
       "95       4.568093      0.610452         0.050315        0.005770   \n",
       "96       9.484884      0.671154         0.072124        0.012675   \n",
       "97       5.383757      0.779638         0.070518        0.030195   \n",
       "98      10.583913      0.775053         0.073162        0.011466   \n",
       "99       4.397454      1.136542         0.040335        0.014535   \n",
       "\n",
       "   param_logistic__C param_logistic__penalty  \\\n",
       "0             0.0001                      l1   \n",
       "1             0.0001                      l2   \n",
       "2        0.000145635                      l1   \n",
       "3        0.000145635                      l2   \n",
       "4        0.000212095                      l1   \n",
       "5        0.000212095                      l2   \n",
       "6        0.000308884                      l1   \n",
       "7        0.000308884                      l2   \n",
       "8        0.000449843                      l1   \n",
       "9        0.000449843                      l2   \n",
       "10       0.000655129                      l1   \n",
       "11       0.000655129                      l2   \n",
       "12       0.000954095                      l1   \n",
       "13       0.000954095                      l2   \n",
       "14         0.0013895                      l1   \n",
       "15         0.0013895                      l2   \n",
       "16        0.00202359                      l1   \n",
       "17        0.00202359                      l2   \n",
       "18        0.00294705                      l1   \n",
       "19        0.00294705                      l2   \n",
       "20        0.00429193                      l1   \n",
       "21        0.00429193                      l2   \n",
       "22        0.00625055                      l1   \n",
       "23        0.00625055                      l2   \n",
       "24        0.00910298                      l1   \n",
       "25        0.00910298                      l2   \n",
       "26         0.0132571                      l1   \n",
       "27         0.0132571                      l2   \n",
       "28          0.019307                      l1   \n",
       "29          0.019307                      l2   \n",
       "..               ...                     ...   \n",
       "70           51.7947                      l1   \n",
       "71           51.7947                      l2   \n",
       "72           75.4312                      l1   \n",
       "73           75.4312                      l2   \n",
       "74           109.854                      l1   \n",
       "75           109.854                      l2   \n",
       "76           159.986                      l1   \n",
       "77           159.986                      l2   \n",
       "78           232.995                      l1   \n",
       "79           232.995                      l2   \n",
       "80           339.322                      l1   \n",
       "81           339.322                      l2   \n",
       "82           494.171                      l1   \n",
       "83           494.171                      l2   \n",
       "84           719.686                      l1   \n",
       "85           719.686                      l2   \n",
       "86           1048.11                      l1   \n",
       "87           1048.11                      l2   \n",
       "88           1526.42                      l1   \n",
       "89           1526.42                      l2   \n",
       "90              2223                      l1   \n",
       "91              2223                      l2   \n",
       "92           3237.46                      l1   \n",
       "93           3237.46                      l2   \n",
       "94           4714.87                      l1   \n",
       "95           4714.87                      l2   \n",
       "96           6866.49                      l1   \n",
       "97           6866.49                      l2   \n",
       "98             10000                      l1   \n",
       "99             10000                      l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.500000   \n",
       "1   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.938569   \n",
       "2   {'logistic__C': 0.00014563484775012445, 'logis...           0.500000   \n",
       "3   {'logistic__C': 0.00014563484775012445, 'logis...           0.949483   \n",
       "4   {'logistic__C': 0.00021209508879201905, 'logis...           0.500000   \n",
       "5   {'logistic__C': 0.00021209508879201905, 'logis...           0.955810   \n",
       "6   {'logistic__C': 0.00030888435964774815, 'logis...           0.500000   \n",
       "7   {'logistic__C': 0.00030888435964774815, 'logis...           0.958557   \n",
       "8   {'logistic__C': 0.0004498432668969444, 'logist...           0.500000   \n",
       "9   {'logistic__C': 0.0004498432668969444, 'logist...           0.960077   \n",
       "10  {'logistic__C': 0.0006551285568595509, 'logist...           0.850704   \n",
       "11  {'logistic__C': 0.0006551285568595509, 'logist...           0.961160   \n",
       "12  {'logistic__C': 0.0009540954763499944, 'logist...           0.908338   \n",
       "13  {'logistic__C': 0.0009540954763499944, 'logist...           0.961959   \n",
       "14  {'logistic__C': 0.0013894954943731374, 'logist...           0.949418   \n",
       "15  {'logistic__C': 0.0013894954943731374, 'logist...           0.962589   \n",
       "16  {'logistic__C': 0.0020235896477251557, 'logist...           0.950841   \n",
       "17  {'logistic__C': 0.0020235896477251557, 'logist...           0.963029   \n",
       "18  {'logistic__C': 0.0029470517025518097, 'logist...           0.951302   \n",
       "19  {'logistic__C': 0.0029470517025518097, 'logist...           0.963345   \n",
       "20  {'logistic__C': 0.004291934260128779, 'logisti...           0.952323   \n",
       "21  {'logistic__C': 0.004291934260128779, 'logisti...           0.963539   \n",
       "22  {'logistic__C': 0.0062505519252739694, 'logist...           0.955290   \n",
       "23  {'logistic__C': 0.0062505519252739694, 'logist...           0.963544   \n",
       "24  {'logistic__C': 0.009102981779915217, 'logisti...           0.957226   \n",
       "25  {'logistic__C': 0.009102981779915217, 'logisti...           0.963401   \n",
       "26  {'logistic__C': 0.013257113655901081, 'logisti...           0.959774   \n",
       "27  {'logistic__C': 0.013257113655901081, 'logisti...           0.963141   \n",
       "28  {'logistic__C': 0.019306977288832496, 'logisti...           0.960940   \n",
       "29  {'logistic__C': 0.019306977288832496, 'logisti...           0.962889   \n",
       "..                                                ...                ...   \n",
       "70  {'logistic__C': 51.79474679231202, 'logistic__...           0.960247   \n",
       "71  {'logistic__C': 51.79474679231202, 'logistic__...           0.960247   \n",
       "72  {'logistic__C': 75.43120063354607, 'logistic__...           0.960244   \n",
       "73  {'logistic__C': 75.43120063354607, 'logistic__...           0.960243   \n",
       "74  {'logistic__C': 109.85411419875572, 'logistic_...           0.960241   \n",
       "75  {'logistic__C': 109.85411419875572, 'logistic_...           0.960242   \n",
       "76  {'logistic__C': 159.98587196060572, 'logistic_...           0.960239   \n",
       "77  {'logistic__C': 159.98587196060572, 'logistic_...           0.960241   \n",
       "78  {'logistic__C': 232.99518105153672, 'logistic_...           0.960238   \n",
       "79  {'logistic__C': 232.99518105153672, 'logistic_...           0.960239   \n",
       "80  {'logistic__C': 339.3221771895323, 'logistic__...           0.960236   \n",
       "81  {'logistic__C': 339.3221771895323, 'logistic__...           0.960237   \n",
       "82  {'logistic__C': 494.1713361323828, 'logistic__...           0.960236   \n",
       "83  {'logistic__C': 494.1713361323828, 'logistic__...           0.960237   \n",
       "84  {'logistic__C': 719.6856730011514, 'logistic__...           0.960236   \n",
       "85  {'logistic__C': 719.6856730011514, 'logistic__...           0.960236   \n",
       "86  {'logistic__C': 1048.1131341546852, 'logistic_...           0.960235   \n",
       "87  {'logistic__C': 1048.1131341546852, 'logistic_...           0.960235   \n",
       "88  {'logistic__C': 1526.4179671752302, 'logistic_...           0.960235   \n",
       "89  {'logistic__C': 1526.4179671752302, 'logistic_...           0.960235   \n",
       "90  {'logistic__C': 2222.996482526191, 'logistic__...           0.960235   \n",
       "91  {'logistic__C': 2222.996482526191, 'logistic__...           0.960235   \n",
       "92  {'logistic__C': 3237.45754281764, 'logistic__p...           0.960236   \n",
       "93  {'logistic__C': 3237.45754281764, 'logistic__p...           0.960235   \n",
       "94  {'logistic__C': 4714.8663634573895, 'logistic_...           0.960236   \n",
       "95  {'logistic__C': 4714.8663634573895, 'logistic_...           0.960235   \n",
       "96  {'logistic__C': 6866.488450042998, 'logistic__...           0.960235   \n",
       "97  {'logistic__C': 6866.488450042998, 'logistic__...           0.960235   \n",
       "98  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.960236   \n",
       "99  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.960235   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.500000           0.500000           0.500000   \n",
       "1            0.955992           0.923399           0.959528   \n",
       "2            0.500000           0.500000           0.500000   \n",
       "3            0.962790           0.945757           0.967712   \n",
       "4            0.500000           0.500000           0.500000   \n",
       "5            0.967489           0.962917           0.976736   \n",
       "6            0.500000           0.500000           0.500000   \n",
       "7            0.971019           0.971460           0.979753   \n",
       "8            0.500000           0.500000           0.500000   \n",
       "9            0.973816           0.977599           0.981605   \n",
       "10           0.831897           0.813248           0.868012   \n",
       "11           0.975958           0.983289           0.982896   \n",
       "12           0.900663           0.855768           0.906539   \n",
       "13           0.977961           0.987348           0.983845   \n",
       "14           0.933744           0.922404           0.936225   \n",
       "15           0.979977           0.989629           0.984577   \n",
       "16           0.941975           0.932822           0.943234   \n",
       "17           0.981739           0.991017           0.985167   \n",
       "18           0.952835           0.940828           0.951472   \n",
       "19           0.983053           0.991884           0.985501   \n",
       "20           0.965110           0.948437           0.957944   \n",
       "21           0.983775           0.992501           0.985553   \n",
       "22           0.973925           0.962230           0.962736   \n",
       "23           0.984132           0.992941           0.985353   \n",
       "24           0.979475           0.975276           0.965908   \n",
       "25           0.984235           0.993284           0.984992   \n",
       "26           0.984209           0.985014           0.968174   \n",
       "27           0.984180           0.993554           0.984563   \n",
       "28           0.987058           0.989361           0.969851   \n",
       "29           0.983933           0.993784           0.984245   \n",
       "..                ...                ...                ...   \n",
       "70           0.980411           0.992720           0.984908   \n",
       "71           0.980410           0.992722           0.984904   \n",
       "72           0.980404           0.992717           0.984906   \n",
       "73           0.980406           0.992720           0.984908   \n",
       "74           0.980401           0.992717           0.984905   \n",
       "75           0.980401           0.992718           0.984906   \n",
       "76           0.980399           0.992717           0.984906   \n",
       "77           0.980399           0.992716           0.984906   \n",
       "78           0.980396           0.992717           0.984906   \n",
       "79           0.980397           0.992716           0.984907   \n",
       "80           0.980395           0.992716           0.984906   \n",
       "81           0.980396           0.992716           0.984908   \n",
       "82           0.980394           0.992716           0.984907   \n",
       "83           0.980394           0.992715           0.984908   \n",
       "84           0.980393           0.992715           0.984908   \n",
       "85           0.980394           0.992715           0.984907   \n",
       "86           0.980392           0.992715           0.984907   \n",
       "87           0.980394           0.992715           0.984907   \n",
       "88           0.980392           0.992715           0.984907   \n",
       "89           0.980394           0.992715           0.984907   \n",
       "90           0.980393           0.992715           0.984907   \n",
       "91           0.980394           0.992715           0.984907   \n",
       "92           0.980393           0.992716           0.984907   \n",
       "93           0.980393           0.992715           0.984907   \n",
       "94           0.980392           0.992716           0.984908   \n",
       "95           0.980393           0.992715           0.984907   \n",
       "96           0.980392           0.992715           0.984907   \n",
       "97           0.980393           0.992715           0.984907   \n",
       "98           0.980392           0.992715           0.984907   \n",
       "99           0.980393           0.992715           0.984907   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.500000         0.500000        0.000000               96  \n",
       "1            0.939764         0.943450        0.013079               91  \n",
       "2            0.500000         0.500000        0.000000               96  \n",
       "3            0.953045         0.955757        0.008235               88  \n",
       "4            0.500000         0.500000        0.000000               96  \n",
       "5            0.957551         0.964101        0.007539               86  \n",
       "6            0.500000         0.500000        0.000000               96  \n",
       "7            0.960127         0.968183        0.007877               84  \n",
       "8            0.500000         0.500000        0.000000               96  \n",
       "9            0.962719         0.971163        0.008387               83  \n",
       "10           0.881864         0.849145        0.024556               95  \n",
       "11           0.965583         0.973777        0.008997               81  \n",
       "12           0.922608         0.898783        0.022684               94  \n",
       "13           0.967937         0.975810        0.009552               79  \n",
       "14           0.943960         0.937150        0.009239               93  \n",
       "15           0.969920         0.977338        0.009828               76  \n",
       "16           0.944597         0.942694        0.005801               92  \n",
       "17           0.971700         0.978530        0.009972               17  \n",
       "18           0.945575         0.948402        0.004535               90  \n",
       "19           0.972871         0.979331        0.010068               10  \n",
       "20           0.949320         0.954627        0.006208               89  \n",
       "21           0.973582         0.979790        0.010132                6  \n",
       "22           0.955206         0.961877        0.006840               87  \n",
       "23           0.974108         0.980015        0.010185                3  \n",
       "24           0.960735         0.967724        0.008455               85  \n",
       "25           0.974471         0.980077        0.010251                1  \n",
       "26           0.965102         0.972455        0.010287               82  \n",
       "27           0.974642         0.980016        0.010343                2  \n",
       "28           0.967401         0.974922        0.011256               80  \n",
       "29           0.974688         0.979908        0.010435                4  \n",
       "..                ...              ...             ...              ...  \n",
       "70           0.968819         0.977421        0.011559               47  \n",
       "71           0.968828         0.977422        0.011557               46  \n",
       "72           0.968820         0.977418        0.011558               49  \n",
       "73           0.968825         0.977420        0.011559               48  \n",
       "74           0.968819         0.977417        0.011559               51  \n",
       "75           0.968822         0.977418        0.011558               50  \n",
       "76           0.968817         0.977415        0.011560               54  \n",
       "77           0.968821         0.977417        0.011558               52  \n",
       "78           0.968817         0.977415        0.011560               56  \n",
       "79           0.968819         0.977416        0.011559               53  \n",
       "80           0.968815         0.977414        0.011560               58  \n",
       "81           0.968817         0.977415        0.011560               55  \n",
       "82           0.968815         0.977414        0.011560               58  \n",
       "83           0.968816         0.977414        0.011560               57  \n",
       "84           0.968815         0.977413        0.011560               60  \n",
       "85           0.968815         0.977413        0.011560               62  \n",
       "86           0.968815         0.977413        0.011560               67  \n",
       "87           0.968815         0.977413        0.011560               61  \n",
       "88           0.968814         0.977413        0.011560               70  \n",
       "89           0.968815         0.977413        0.011560               65  \n",
       "90           0.968815         0.977413        0.011560               68  \n",
       "91           0.968815         0.977413        0.011560               66  \n",
       "92           0.968814         0.977413        0.011560               64  \n",
       "93           0.968815         0.977413        0.011560               69  \n",
       "94           0.968815         0.977413        0.011560               63  \n",
       "95           0.968814         0.977413        0.011560               71  \n",
       "96           0.968814         0.977413        0.011560               73  \n",
       "97           0.968814         0.977413        0.011561               74  \n",
       "98           0.968814         0.977413        0.011560               72  \n",
       "99           0.968814         0.977413        0.011561               75  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation results\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Applying SMOTE Technique on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for \"imblearn package\" installing use pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smt.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426472, 30)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426472,)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance in The Data :  1.0\n"
     ]
    }
   ],
   "source": [
    "#Checking imbalance rate\n",
    "churn_rate = (y_train_balanced == 1).sum()/(y_train_balanced == 0).sum()\n",
    "print(\"Imbalance in The Data : \",churn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression with balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-04 1.45634848e-04 2.12095089e-04 3.08884360e-04\n",
      " 4.49843267e-04 6.55128557e-04 9.54095476e-04 1.38949549e-03\n",
      " 2.02358965e-03 2.94705170e-03 4.29193426e-03 6.25055193e-03\n",
      " 9.10298178e-03 1.32571137e-02 1.93069773e-02 2.81176870e-02\n",
      " 4.09491506e-02 5.96362332e-02 8.68511374e-02 1.26485522e-01\n",
      " 1.84206997e-01 2.68269580e-01 3.90693994e-01 5.68986603e-01\n",
      " 8.28642773e-01 1.20679264e+00 1.75751062e+00 2.55954792e+00\n",
      " 3.72759372e+00 5.42867544e+00 7.90604321e+00 1.15139540e+01\n",
      " 1.67683294e+01 2.44205309e+01 3.55648031e+01 5.17947468e+01\n",
      " 7.54312006e+01 1.09854114e+02 1.59985872e+02 2.32995181e+02\n",
      " 3.39322177e+02 4.94171336e+02 7.19685673e+02 1.04811313e+03\n",
      " 1.52641797e+03 2.22299648e+03 3.23745754e+03 4.71486636e+03\n",
      " 6.86648845e+03 1.00000000e+04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model #import the package\n",
    "\n",
    "num_C =  np.logspace(-4, 4, 50)  #--> list of values\n",
    "cv_num =num_C   #--> list of values\n",
    "print(num_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameter Tunning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "logistic = linear_model.LogisticRegression(class_weight={0:0.1, 1: 0.9})\n",
    "steps = [\n",
    "        \n",
    "         (\"logistic\",logistic )\n",
    "        ]\n",
    "logistic_pipeline = Pipeline(steps)\n",
    "# Create a list of options for the regularization penalty\n",
    "#penalty = ['l1', 'l2']\n",
    "\n",
    "params = { 'logistic__C': num_C, 'logistic__penalty': ['l1', 'l2']}\n",
    "\n",
    "\n",
    "# create gridsearch object\n",
    "clf = GridSearchCV(estimator=logistic_pipeline, cv=skf, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 19.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('logistic',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight={0: 0.1,\n",
       "                                                                         1: 0.9},\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           s...\n",
       "       1.67683294e+01, 2.44205309e+01, 3.55648031e+01, 5.17947468e+01,\n",
       "       7.54312006e+01, 1.09854114e+02, 1.59985872e+02, 2.32995181e+02,\n",
       "       3.39322177e+02, 4.94171336e+02, 7.19685673e+02, 1.04811313e+03,\n",
       "       1.52641797e+03, 2.22299648e+03, 3.23745754e+03, 4.71486636e+03,\n",
       "       6.86648845e+03, 1.00000000e+04]),\n",
       "                         'logistic__penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model \n",
    "clf.fit(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC:  0.9910437542581414\n",
      "Best hyperparameters:  {'logistic__C': 2222.996482526191, 'logistic__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", clf.best_score_)\n",
    "print(\"Best hyperparameters: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of test data:    \t 0.99\n"
     ]
    }
   ],
   "source": [
    "#Evaluate on test data \n",
    "from sklearn.metrics import roc_auc_score\n",
    "# predict  on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "# check area under curve\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC of test data:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_logistic__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.317338</td>\n",
       "      <td>0.639561</td>\n",
       "      <td>0.086621</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.976056</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>0.975241</td>\n",
       "      <td>0.974843</td>\n",
       "      <td>0.977626</td>\n",
       "      <td>0.975778</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.315158</td>\n",
       "      <td>0.029815</td>\n",
       "      <td>0.078366</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0001, 'logistic__penalty': '...</td>\n",
       "      <td>0.989321</td>\n",
       "      <td>0.988950</td>\n",
       "      <td>0.989183</td>\n",
       "      <td>0.989414</td>\n",
       "      <td>0.989937</td>\n",
       "      <td>0.989361</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.612010</td>\n",
       "      <td>0.205056</td>\n",
       "      <td>0.076814</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.000145635</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00014563484775012445, 'logis...</td>\n",
       "      <td>0.980153</td>\n",
       "      <td>0.979297</td>\n",
       "      <td>0.979246</td>\n",
       "      <td>0.979315</td>\n",
       "      <td>0.981275</td>\n",
       "      <td>0.979857</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.781499</td>\n",
       "      <td>0.091187</td>\n",
       "      <td>0.093549</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.000145635</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00014563484775012445, 'logis...</td>\n",
       "      <td>0.989443</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>0.989293</td>\n",
       "      <td>0.989544</td>\n",
       "      <td>0.990014</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.391720</td>\n",
       "      <td>0.218521</td>\n",
       "      <td>0.068542</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.000212095</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00021209508879201905, 'logis...</td>\n",
       "      <td>0.981665</td>\n",
       "      <td>0.981091</td>\n",
       "      <td>0.980819</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.982692</td>\n",
       "      <td>0.981535</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.727807</td>\n",
       "      <td>0.058360</td>\n",
       "      <td>0.086514</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.000212095</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00021209508879201905, 'logis...</td>\n",
       "      <td>0.989524</td>\n",
       "      <td>0.989158</td>\n",
       "      <td>0.989365</td>\n",
       "      <td>0.989635</td>\n",
       "      <td>0.990064</td>\n",
       "      <td>0.989549</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.185152</td>\n",
       "      <td>0.128545</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.000308884</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.00030888435964774815, 'logis...</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>0.982477</td>\n",
       "      <td>0.982144</td>\n",
       "      <td>0.982729</td>\n",
       "      <td>0.984076</td>\n",
       "      <td>0.982909</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.653310</td>\n",
       "      <td>0.109265</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.000308884</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.00030888435964774815, 'logis...</td>\n",
       "      <td>0.989592</td>\n",
       "      <td>0.989230</td>\n",
       "      <td>0.989422</td>\n",
       "      <td>0.989708</td>\n",
       "      <td>0.990105</td>\n",
       "      <td>0.989612</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.370058</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.065167</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.000449843</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0004498432668969444, 'logist...</td>\n",
       "      <td>0.984148</td>\n",
       "      <td>0.983552</td>\n",
       "      <td>0.983367</td>\n",
       "      <td>0.983957</td>\n",
       "      <td>0.985016</td>\n",
       "      <td>0.984008</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.233476</td>\n",
       "      <td>0.056810</td>\n",
       "      <td>0.085140</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.000449843</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0004498432668969444, 'logist...</td>\n",
       "      <td>0.989660</td>\n",
       "      <td>0.989297</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.989775</td>\n",
       "      <td>0.990144</td>\n",
       "      <td>0.989670</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.505867</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.068482</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.000655129</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0006551285568595509, 'logist...</td>\n",
       "      <td>0.986347</td>\n",
       "      <td>0.985848</td>\n",
       "      <td>0.985835</td>\n",
       "      <td>0.986400</td>\n",
       "      <td>0.987198</td>\n",
       "      <td>0.986326</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.452280</td>\n",
       "      <td>0.108233</td>\n",
       "      <td>0.083349</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000655129</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0006551285568595509, 'logist...</td>\n",
       "      <td>0.989723</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>0.989531</td>\n",
       "      <td>0.989847</td>\n",
       "      <td>0.990205</td>\n",
       "      <td>0.989736</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.849157</td>\n",
       "      <td>0.197310</td>\n",
       "      <td>0.071611</td>\n",
       "      <td>0.003434</td>\n",
       "      <td>0.000954095</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0009540954763499944, 'logist...</td>\n",
       "      <td>0.988005</td>\n",
       "      <td>0.987593</td>\n",
       "      <td>0.987646</td>\n",
       "      <td>0.988106</td>\n",
       "      <td>0.988656</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.557429</td>\n",
       "      <td>0.174502</td>\n",
       "      <td>0.084651</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.000954095</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0009540954763499944, 'logist...</td>\n",
       "      <td>0.989826</td>\n",
       "      <td>0.989476</td>\n",
       "      <td>0.989626</td>\n",
       "      <td>0.989946</td>\n",
       "      <td>0.990292</td>\n",
       "      <td>0.989833</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.296388</td>\n",
       "      <td>0.147402</td>\n",
       "      <td>0.074514</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.0013895</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0013894954943731374, 'logist...</td>\n",
       "      <td>0.988854</td>\n",
       "      <td>0.988504</td>\n",
       "      <td>0.988587</td>\n",
       "      <td>0.988995</td>\n",
       "      <td>0.989393</td>\n",
       "      <td>0.988867</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.727020</td>\n",
       "      <td>0.195046</td>\n",
       "      <td>0.082364</td>\n",
       "      <td>0.006005</td>\n",
       "      <td>0.0013895</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0013894954943731374, 'logist...</td>\n",
       "      <td>0.989980</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>0.989744</td>\n",
       "      <td>0.990063</td>\n",
       "      <td>0.990407</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.789880</td>\n",
       "      <td>0.274044</td>\n",
       "      <td>0.073597</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.00202359</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0020235896477251557, 'logist...</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.989024</td>\n",
       "      <td>0.989110</td>\n",
       "      <td>0.989489</td>\n",
       "      <td>0.989816</td>\n",
       "      <td>0.989356</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.181957</td>\n",
       "      <td>0.185527</td>\n",
       "      <td>0.087237</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.00202359</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0020235896477251557, 'logist...</td>\n",
       "      <td>0.990136</td>\n",
       "      <td>0.989779</td>\n",
       "      <td>0.989929</td>\n",
       "      <td>0.990240</td>\n",
       "      <td>0.990575</td>\n",
       "      <td>0.990132</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.266699</td>\n",
       "      <td>0.344260</td>\n",
       "      <td>0.076751</td>\n",
       "      <td>0.005436</td>\n",
       "      <td>0.00294705</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0029470517025518097, 'logist...</td>\n",
       "      <td>0.989665</td>\n",
       "      <td>0.989334</td>\n",
       "      <td>0.989440</td>\n",
       "      <td>0.989792</td>\n",
       "      <td>0.990096</td>\n",
       "      <td>0.989665</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.581207</td>\n",
       "      <td>0.177346</td>\n",
       "      <td>0.084707</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.00294705</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0029470517025518097, 'logist...</td>\n",
       "      <td>0.990312</td>\n",
       "      <td>0.989957</td>\n",
       "      <td>0.990111</td>\n",
       "      <td>0.990420</td>\n",
       "      <td>0.990740</td>\n",
       "      <td>0.990308</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.607292</td>\n",
       "      <td>0.364467</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.00429193</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.004291934260128779, 'logisti...</td>\n",
       "      <td>0.989841</td>\n",
       "      <td>0.989527</td>\n",
       "      <td>0.989619</td>\n",
       "      <td>0.989984</td>\n",
       "      <td>0.990277</td>\n",
       "      <td>0.989849</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.076833</td>\n",
       "      <td>0.571808</td>\n",
       "      <td>0.088720</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.00429193</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.004291934260128779, 'logisti...</td>\n",
       "      <td>0.990479</td>\n",
       "      <td>0.990139</td>\n",
       "      <td>0.990309</td>\n",
       "      <td>0.990599</td>\n",
       "      <td>0.990907</td>\n",
       "      <td>0.990486</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7.447881</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.080806</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>0.00625055</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.0062505519252739694, 'logist...</td>\n",
       "      <td>0.990174</td>\n",
       "      <td>0.989868</td>\n",
       "      <td>0.989943</td>\n",
       "      <td>0.990358</td>\n",
       "      <td>0.990611</td>\n",
       "      <td>0.990191</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7.095806</td>\n",
       "      <td>0.350859</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.00625055</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.0062505519252739694, 'logist...</td>\n",
       "      <td>0.990620</td>\n",
       "      <td>0.990298</td>\n",
       "      <td>0.990467</td>\n",
       "      <td>0.990754</td>\n",
       "      <td>0.991045</td>\n",
       "      <td>0.990637</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.320810</td>\n",
       "      <td>0.936721</td>\n",
       "      <td>0.080269</td>\n",
       "      <td>0.010141</td>\n",
       "      <td>0.00910298</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.009102981779915217, 'logisti...</td>\n",
       "      <td>0.990513</td>\n",
       "      <td>0.990207</td>\n",
       "      <td>0.990330</td>\n",
       "      <td>0.990692</td>\n",
       "      <td>0.990947</td>\n",
       "      <td>0.990538</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.240008</td>\n",
       "      <td>0.471021</td>\n",
       "      <td>0.090040</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.00910298</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.009102981779915217, 'logisti...</td>\n",
       "      <td>0.990739</td>\n",
       "      <td>0.990427</td>\n",
       "      <td>0.990590</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.990758</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.386187</td>\n",
       "      <td>0.320893</td>\n",
       "      <td>0.075988</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.0132571</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.013257113655901081, 'logisti...</td>\n",
       "      <td>0.990697</td>\n",
       "      <td>0.990396</td>\n",
       "      <td>0.990547</td>\n",
       "      <td>0.990876</td>\n",
       "      <td>0.991127</td>\n",
       "      <td>0.990728</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.208327</td>\n",
       "      <td>0.513952</td>\n",
       "      <td>0.087956</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.0132571</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.013257113655901081, 'logisti...</td>\n",
       "      <td>0.990829</td>\n",
       "      <td>0.990528</td>\n",
       "      <td>0.990688</td>\n",
       "      <td>0.990975</td>\n",
       "      <td>0.991243</td>\n",
       "      <td>0.990852</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.303418</td>\n",
       "      <td>1.133222</td>\n",
       "      <td>0.081207</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 0.019306977288832496, 'logisti...</td>\n",
       "      <td>0.990796</td>\n",
       "      <td>0.990516</td>\n",
       "      <td>0.990676</td>\n",
       "      <td>0.990963</td>\n",
       "      <td>0.991220</td>\n",
       "      <td>0.990834</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.373440</td>\n",
       "      <td>0.665144</td>\n",
       "      <td>0.086960</td>\n",
       "      <td>0.011034</td>\n",
       "      <td>0.019307</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 0.019306977288832496, 'logisti...</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.990605</td>\n",
       "      <td>0.990755</td>\n",
       "      <td>0.991039</td>\n",
       "      <td>0.991317</td>\n",
       "      <td>0.990922</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>11.452943</td>\n",
       "      <td>0.564227</td>\n",
       "      <td>0.087257</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>51.7947</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 51.79474679231202, 'logistic__...</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.990733</td>\n",
       "      <td>0.990871</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>9.549277</td>\n",
       "      <td>0.362574</td>\n",
       "      <td>0.095897</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>51.7947</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 51.79474679231202, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.271160</td>\n",
       "      <td>1.285593</td>\n",
       "      <td>0.101165</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>75.4312</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 75.43120063354607, 'logistic__...</td>\n",
       "      <td>0.991005</td>\n",
       "      <td>0.990733</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.991424</td>\n",
       "      <td>0.991036</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>9.592408</td>\n",
       "      <td>0.653947</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.017929</td>\n",
       "      <td>75.4312</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 75.43120063354607, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>13.027748</td>\n",
       "      <td>1.905911</td>\n",
       "      <td>0.084172</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>109.854</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 109.85411419875572, 'logistic_...</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.991146</td>\n",
       "      <td>0.991428</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>9.359178</td>\n",
       "      <td>0.401560</td>\n",
       "      <td>0.091305</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>109.854</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 109.85411419875572, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990745</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>12.093559</td>\n",
       "      <td>1.331989</td>\n",
       "      <td>0.085051</td>\n",
       "      <td>0.010183</td>\n",
       "      <td>159.986</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 159.98587196060572, 'logistic_...</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.990737</td>\n",
       "      <td>0.990869</td>\n",
       "      <td>0.991140</td>\n",
       "      <td>0.991427</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>9.288792</td>\n",
       "      <td>0.404093</td>\n",
       "      <td>0.085592</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>159.986</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 159.98587196060572, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>12.355773</td>\n",
       "      <td>1.698329</td>\n",
       "      <td>0.086722</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>232.995</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 232.99518105153672, 'logistic_...</td>\n",
       "      <td>0.991005</td>\n",
       "      <td>0.990748</td>\n",
       "      <td>0.990867</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991430</td>\n",
       "      <td>0.991040</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>9.227432</td>\n",
       "      <td>0.429091</td>\n",
       "      <td>0.089062</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>232.995</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 232.99518105153672, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>11.949588</td>\n",
       "      <td>1.126557</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>339.322</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 339.3221771895323, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990733</td>\n",
       "      <td>0.990869</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.991427</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>9.288898</td>\n",
       "      <td>0.644076</td>\n",
       "      <td>0.083531</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>339.322</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 339.3221771895323, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>11.978116</td>\n",
       "      <td>0.572484</td>\n",
       "      <td>0.088342</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>494.171</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 494.1713361323828, 'logistic__...</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.990736</td>\n",
       "      <td>0.990870</td>\n",
       "      <td>0.991146</td>\n",
       "      <td>0.991434</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9.566605</td>\n",
       "      <td>0.363398</td>\n",
       "      <td>0.088116</td>\n",
       "      <td>0.011856</td>\n",
       "      <td>494.171</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 494.1713361323828, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>11.610430</td>\n",
       "      <td>0.692290</td>\n",
       "      <td>0.083577</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>719.686</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 719.6856730011514, 'logistic__...</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.990727</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.991424</td>\n",
       "      <td>0.991034</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>9.186444</td>\n",
       "      <td>0.641687</td>\n",
       "      <td>0.086317</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>719.686</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 719.6856730011514, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>11.935953</td>\n",
       "      <td>1.333797</td>\n",
       "      <td>0.079551</td>\n",
       "      <td>0.007699</td>\n",
       "      <td>1048.11</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 1048.1131341546852, 'logistic_...</td>\n",
       "      <td>0.991003</td>\n",
       "      <td>0.990732</td>\n",
       "      <td>0.990871</td>\n",
       "      <td>0.991146</td>\n",
       "      <td>0.991424</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>9.294926</td>\n",
       "      <td>0.463627</td>\n",
       "      <td>0.091780</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>1048.11</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 1048.1131341546852, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12.317021</td>\n",
       "      <td>0.985813</td>\n",
       "      <td>0.083304</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>1526.42</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 1526.4179671752302, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990732</td>\n",
       "      <td>0.990869</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991429</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9.403632</td>\n",
       "      <td>0.636956</td>\n",
       "      <td>0.082811</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>1526.42</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 1526.4179671752302, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>11.009351</td>\n",
       "      <td>1.193995</td>\n",
       "      <td>0.081650</td>\n",
       "      <td>0.011584</td>\n",
       "      <td>2223</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 2222.996482526191, 'logistic__...</td>\n",
       "      <td>0.990997</td>\n",
       "      <td>0.990733</td>\n",
       "      <td>0.990874</td>\n",
       "      <td>0.991145</td>\n",
       "      <td>0.991421</td>\n",
       "      <td>0.991034</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9.222435</td>\n",
       "      <td>0.461742</td>\n",
       "      <td>0.087198</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>2223</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 2222.996482526191, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11.490552</td>\n",
       "      <td>0.670424</td>\n",
       "      <td>0.087731</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>3237.46</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 3237.45754281764, 'logistic__p...</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.990736</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>0.991038</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.814425</td>\n",
       "      <td>0.522607</td>\n",
       "      <td>0.092840</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>3237.46</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 3237.45754281764, 'logistic__p...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>11.921689</td>\n",
       "      <td>0.801310</td>\n",
       "      <td>0.094925</td>\n",
       "      <td>0.015473</td>\n",
       "      <td>4714.87</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 4714.8663634573895, 'logistic_...</td>\n",
       "      <td>0.991007</td>\n",
       "      <td>0.990730</td>\n",
       "      <td>0.990862</td>\n",
       "      <td>0.991142</td>\n",
       "      <td>0.991434</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9.988409</td>\n",
       "      <td>0.426257</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>4714.87</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 4714.8663634573895, 'logistic_...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12.908440</td>\n",
       "      <td>0.674467</td>\n",
       "      <td>0.078779</td>\n",
       "      <td>0.008204</td>\n",
       "      <td>6866.49</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 6866.488450042998, 'logistic__...</td>\n",
       "      <td>0.991008</td>\n",
       "      <td>0.990737</td>\n",
       "      <td>0.990868</td>\n",
       "      <td>0.991151</td>\n",
       "      <td>0.991444</td>\n",
       "      <td>0.991042</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10.269993</td>\n",
       "      <td>0.546928</td>\n",
       "      <td>0.101724</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>6866.49</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 6866.488450042998, 'logistic__...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>12.236844</td>\n",
       "      <td>0.734150</td>\n",
       "      <td>0.080701</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>10000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.990728</td>\n",
       "      <td>0.990867</td>\n",
       "      <td>0.991144</td>\n",
       "      <td>0.991430</td>\n",
       "      <td>0.991034</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>8.334433</td>\n",
       "      <td>1.250984</td>\n",
       "      <td>0.067381</td>\n",
       "      <td>0.017417</td>\n",
       "      <td>10000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logistic__C': 10000.0, 'logistic__penalty': ...</td>\n",
       "      <td>0.991006</td>\n",
       "      <td>0.990746</td>\n",
       "      <td>0.990879</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.991439</td>\n",
       "      <td>0.991044</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        4.317338      0.639561         0.086621        0.003022   \n",
       "1        4.315158      0.029815         0.078366        0.009400   \n",
       "2        3.612010      0.205056         0.076814        0.014736   \n",
       "3        4.781499      0.091187         0.093549        0.014385   \n",
       "4        3.391720      0.218521         0.068542        0.002411   \n",
       "5        4.727807      0.058360         0.086514        0.003825   \n",
       "6        3.185152      0.128545         0.070380        0.006659   \n",
       "7        4.653310      0.109265         0.082501        0.009313   \n",
       "8        3.370058      0.051167         0.065167        0.008242   \n",
       "9        5.233476      0.056810         0.085140        0.004252   \n",
       "10       3.505867      0.038337         0.068482        0.004555   \n",
       "11       5.452280      0.108233         0.083349        0.004038   \n",
       "12       3.849157      0.197310         0.071611        0.003434   \n",
       "13       5.557429      0.174502         0.084651        0.007138   \n",
       "14       4.296388      0.147402         0.074514        0.008989   \n",
       "15       5.727020      0.195046         0.082364        0.006005   \n",
       "16       4.789880      0.274044         0.073597        0.009105   \n",
       "17       6.181957      0.185527         0.087237        0.005923   \n",
       "18       5.266699      0.344260         0.076751        0.005436   \n",
       "19       6.581207      0.177346         0.084707        0.006603   \n",
       "20       5.607292      0.364467         0.081575        0.006978   \n",
       "21       7.076833      0.571808         0.088720        0.009080   \n",
       "22       7.447881      0.263000         0.080806        0.011891   \n",
       "23       7.095806      0.350859         0.086053        0.010058   \n",
       "24       8.320810      0.936721         0.080269        0.010141   \n",
       "25       7.240008      0.471021         0.090040        0.004698   \n",
       "26       8.386187      0.320893         0.075988        0.004244   \n",
       "27       8.208327      0.513952         0.087956        0.006019   \n",
       "28       9.303418      1.133222         0.081207        0.013649   \n",
       "29       8.373440      0.665144         0.086960        0.011034   \n",
       "..            ...           ...              ...             ...   \n",
       "70      11.452943      0.564227         0.087257        0.009510   \n",
       "71       9.549277      0.362574         0.095897        0.012643   \n",
       "72      13.271160      1.285593         0.101165        0.009199   \n",
       "73       9.592408      0.653947         0.092523        0.017929   \n",
       "74      13.027748      1.905911         0.084172        0.012725   \n",
       "75       9.359178      0.401560         0.091305        0.012868   \n",
       "76      12.093559      1.331989         0.085051        0.010183   \n",
       "77       9.288792      0.404093         0.085592        0.006852   \n",
       "78      12.355773      1.698329         0.086722        0.008061   \n",
       "79       9.227432      0.429091         0.089062        0.011355   \n",
       "80      11.949588      1.126557         0.084648        0.007915   \n",
       "81       9.288898      0.644076         0.083531        0.005548   \n",
       "82      11.978116      0.572484         0.088342        0.015357   \n",
       "83       9.566605      0.363398         0.088116        0.011856   \n",
       "84      11.610430      0.692290         0.083577        0.010524   \n",
       "85       9.186444      0.641687         0.086317        0.009696   \n",
       "86      11.935953      1.333797         0.079551        0.007699   \n",
       "87       9.294926      0.463627         0.091780        0.008868   \n",
       "88      12.317021      0.985813         0.083304        0.010848   \n",
       "89       9.403632      0.636956         0.082811        0.007933   \n",
       "90      11.009351      1.193995         0.081650        0.011584   \n",
       "91       9.222435      0.461742         0.087198        0.007806   \n",
       "92      11.490552      0.670424         0.087731        0.014415   \n",
       "93       9.814425      0.522607         0.092840        0.009770   \n",
       "94      11.921689      0.801310         0.094925        0.015473   \n",
       "95       9.988409      0.426257         0.089941        0.011105   \n",
       "96      12.908440      0.674467         0.078779        0.008204   \n",
       "97      10.269993      0.546928         0.101724        0.012399   \n",
       "98      12.236844      0.734150         0.080701        0.007199   \n",
       "99       8.334433      1.250984         0.067381        0.017417   \n",
       "\n",
       "   param_logistic__C param_logistic__penalty  \\\n",
       "0             0.0001                      l1   \n",
       "1             0.0001                      l2   \n",
       "2        0.000145635                      l1   \n",
       "3        0.000145635                      l2   \n",
       "4        0.000212095                      l1   \n",
       "5        0.000212095                      l2   \n",
       "6        0.000308884                      l1   \n",
       "7        0.000308884                      l2   \n",
       "8        0.000449843                      l1   \n",
       "9        0.000449843                      l2   \n",
       "10       0.000655129                      l1   \n",
       "11       0.000655129                      l2   \n",
       "12       0.000954095                      l1   \n",
       "13       0.000954095                      l2   \n",
       "14         0.0013895                      l1   \n",
       "15         0.0013895                      l2   \n",
       "16        0.00202359                      l1   \n",
       "17        0.00202359                      l2   \n",
       "18        0.00294705                      l1   \n",
       "19        0.00294705                      l2   \n",
       "20        0.00429193                      l1   \n",
       "21        0.00429193                      l2   \n",
       "22        0.00625055                      l1   \n",
       "23        0.00625055                      l2   \n",
       "24        0.00910298                      l1   \n",
       "25        0.00910298                      l2   \n",
       "26         0.0132571                      l1   \n",
       "27         0.0132571                      l2   \n",
       "28          0.019307                      l1   \n",
       "29          0.019307                      l2   \n",
       "..               ...                     ...   \n",
       "70           51.7947                      l1   \n",
       "71           51.7947                      l2   \n",
       "72           75.4312                      l1   \n",
       "73           75.4312                      l2   \n",
       "74           109.854                      l1   \n",
       "75           109.854                      l2   \n",
       "76           159.986                      l1   \n",
       "77           159.986                      l2   \n",
       "78           232.995                      l1   \n",
       "79           232.995                      l2   \n",
       "80           339.322                      l1   \n",
       "81           339.322                      l2   \n",
       "82           494.171                      l1   \n",
       "83           494.171                      l2   \n",
       "84           719.686                      l1   \n",
       "85           719.686                      l2   \n",
       "86           1048.11                      l1   \n",
       "87           1048.11                      l2   \n",
       "88           1526.42                      l1   \n",
       "89           1526.42                      l2   \n",
       "90              2223                      l1   \n",
       "91              2223                      l2   \n",
       "92           3237.46                      l1   \n",
       "93           3237.46                      l2   \n",
       "94           4714.87                      l1   \n",
       "95           4714.87                      l2   \n",
       "96           6866.49                      l1   \n",
       "97           6866.49                      l2   \n",
       "98             10000                      l1   \n",
       "99             10000                      l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.976056   \n",
       "1   {'logistic__C': 0.0001, 'logistic__penalty': '...           0.989321   \n",
       "2   {'logistic__C': 0.00014563484775012445, 'logis...           0.980153   \n",
       "3   {'logistic__C': 0.00014563484775012445, 'logis...           0.989443   \n",
       "4   {'logistic__C': 0.00021209508879201905, 'logis...           0.981665   \n",
       "5   {'logistic__C': 0.00021209508879201905, 'logis...           0.989524   \n",
       "6   {'logistic__C': 0.00030888435964774815, 'logis...           0.983118   \n",
       "7   {'logistic__C': 0.00030888435964774815, 'logis...           0.989592   \n",
       "8   {'logistic__C': 0.0004498432668969444, 'logist...           0.984148   \n",
       "9   {'logistic__C': 0.0004498432668969444, 'logist...           0.989660   \n",
       "10  {'logistic__C': 0.0006551285568595509, 'logist...           0.986347   \n",
       "11  {'logistic__C': 0.0006551285568595509, 'logist...           0.989723   \n",
       "12  {'logistic__C': 0.0009540954763499944, 'logist...           0.988005   \n",
       "13  {'logistic__C': 0.0009540954763499944, 'logist...           0.989826   \n",
       "14  {'logistic__C': 0.0013894954943731374, 'logist...           0.988854   \n",
       "15  {'logistic__C': 0.0013894954943731374, 'logist...           0.989980   \n",
       "16  {'logistic__C': 0.0020235896477251557, 'logist...           0.989340   \n",
       "17  {'logistic__C': 0.0020235896477251557, 'logist...           0.990136   \n",
       "18  {'logistic__C': 0.0029470517025518097, 'logist...           0.989665   \n",
       "19  {'logistic__C': 0.0029470517025518097, 'logist...           0.990312   \n",
       "20  {'logistic__C': 0.004291934260128779, 'logisti...           0.989841   \n",
       "21  {'logistic__C': 0.004291934260128779, 'logisti...           0.990479   \n",
       "22  {'logistic__C': 0.0062505519252739694, 'logist...           0.990174   \n",
       "23  {'logistic__C': 0.0062505519252739694, 'logist...           0.990620   \n",
       "24  {'logistic__C': 0.009102981779915217, 'logisti...           0.990513   \n",
       "25  {'logistic__C': 0.009102981779915217, 'logisti...           0.990739   \n",
       "26  {'logistic__C': 0.013257113655901081, 'logisti...           0.990697   \n",
       "27  {'logistic__C': 0.013257113655901081, 'logisti...           0.990829   \n",
       "28  {'logistic__C': 0.019306977288832496, 'logisti...           0.990796   \n",
       "29  {'logistic__C': 0.019306977288832496, 'logisti...           0.990893   \n",
       "..                                                ...                ...   \n",
       "70  {'logistic__C': 51.79474679231202, 'logistic__...           0.991001   \n",
       "71  {'logistic__C': 51.79474679231202, 'logistic__...           0.991006   \n",
       "72  {'logistic__C': 75.43120063354607, 'logistic__...           0.991005   \n",
       "73  {'logistic__C': 75.43120063354607, 'logistic__...           0.991006   \n",
       "74  {'logistic__C': 109.85411419875572, 'logistic_...           0.991004   \n",
       "75  {'logistic__C': 109.85411419875572, 'logistic_...           0.991006   \n",
       "76  {'logistic__C': 159.98587196060572, 'logistic_...           0.991004   \n",
       "77  {'logistic__C': 159.98587196060572, 'logistic_...           0.991006   \n",
       "78  {'logistic__C': 232.99518105153672, 'logistic_...           0.991005   \n",
       "79  {'logistic__C': 232.99518105153672, 'logistic_...           0.991006   \n",
       "80  {'logistic__C': 339.3221771895323, 'logistic__...           0.991006   \n",
       "81  {'logistic__C': 339.3221771895323, 'logistic__...           0.991006   \n",
       "82  {'logistic__C': 494.1713361323828, 'logistic__...           0.991001   \n",
       "83  {'logistic__C': 494.1713361323828, 'logistic__...           0.991006   \n",
       "84  {'logistic__C': 719.6856730011514, 'logistic__...           0.991004   \n",
       "85  {'logistic__C': 719.6856730011514, 'logistic__...           0.991006   \n",
       "86  {'logistic__C': 1048.1131341546852, 'logistic_...           0.991003   \n",
       "87  {'logistic__C': 1048.1131341546852, 'logistic_...           0.991006   \n",
       "88  {'logistic__C': 1526.4179671752302, 'logistic_...           0.991006   \n",
       "89  {'logistic__C': 1526.4179671752302, 'logistic_...           0.991006   \n",
       "90  {'logistic__C': 2222.996482526191, 'logistic__...           0.990997   \n",
       "91  {'logistic__C': 2222.996482526191, 'logistic__...           0.991006   \n",
       "92  {'logistic__C': 3237.45754281764, 'logistic__p...           0.991001   \n",
       "93  {'logistic__C': 3237.45754281764, 'logistic__p...           0.991006   \n",
       "94  {'logistic__C': 4714.8663634573895, 'logistic_...           0.991007   \n",
       "95  {'logistic__C': 4714.8663634573895, 'logistic_...           0.991006   \n",
       "96  {'logistic__C': 6866.488450042998, 'logistic__...           0.991008   \n",
       "97  {'logistic__C': 6866.488450042998, 'logistic__...           0.991006   \n",
       "98  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.991001   \n",
       "99  {'logistic__C': 10000.0, 'logistic__penalty': ...           0.991006   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.975122           0.975241           0.974843   \n",
       "1            0.988950           0.989183           0.989414   \n",
       "2            0.979297           0.979246           0.979315   \n",
       "3            0.989078           0.989293           0.989544   \n",
       "4            0.981091           0.980819           0.981408   \n",
       "5            0.989158           0.989365           0.989635   \n",
       "6            0.982477           0.982144           0.982729   \n",
       "7            0.989230           0.989422           0.989708   \n",
       "8            0.983552           0.983367           0.983957   \n",
       "9            0.989297           0.989474           0.989775   \n",
       "10           0.985848           0.985835           0.986400   \n",
       "11           0.989373           0.989531           0.989847   \n",
       "12           0.987593           0.987646           0.988106   \n",
       "13           0.989476           0.989626           0.989946   \n",
       "14           0.988504           0.988587           0.988995   \n",
       "15           0.989600           0.989744           0.990063   \n",
       "16           0.989024           0.989110           0.989489   \n",
       "17           0.989779           0.989929           0.990240   \n",
       "18           0.989334           0.989440           0.989792   \n",
       "19           0.989957           0.990111           0.990420   \n",
       "20           0.989527           0.989619           0.989984   \n",
       "21           0.990139           0.990309           0.990599   \n",
       "22           0.989868           0.989943           0.990358   \n",
       "23           0.990298           0.990467           0.990754   \n",
       "24           0.990207           0.990330           0.990692   \n",
       "25           0.990427           0.990590           0.990879   \n",
       "26           0.990396           0.990547           0.990876   \n",
       "27           0.990528           0.990688           0.990975   \n",
       "28           0.990516           0.990676           0.990963   \n",
       "29           0.990605           0.990755           0.991039   \n",
       "..                ...                ...                ...   \n",
       "70           0.990733           0.990871           0.991148   \n",
       "71           0.990745           0.990879           0.991148   \n",
       "72           0.990733           0.990868           0.991150   \n",
       "73           0.990745           0.990879           0.991148   \n",
       "74           0.990746           0.990868           0.991146   \n",
       "75           0.990745           0.990879           0.991148   \n",
       "76           0.990737           0.990869           0.991140   \n",
       "77           0.990746           0.990879           0.991148   \n",
       "78           0.990748           0.990867           0.991148   \n",
       "79           0.990746           0.990879           0.991148   \n",
       "80           0.990733           0.990869           0.991150   \n",
       "81           0.990746           0.990879           0.991148   \n",
       "82           0.990736           0.990870           0.991146   \n",
       "83           0.990746           0.990879           0.991148   \n",
       "84           0.990727           0.990868           0.991150   \n",
       "85           0.990746           0.990879           0.991148   \n",
       "86           0.990732           0.990871           0.991146   \n",
       "87           0.990746           0.990879           0.991148   \n",
       "88           0.990732           0.990869           0.991148   \n",
       "89           0.990746           0.990879           0.991148   \n",
       "90           0.990733           0.990874           0.991145   \n",
       "91           0.990746           0.990879           0.991148   \n",
       "92           0.990736           0.990868           0.991150   \n",
       "93           0.990746           0.990879           0.991148   \n",
       "94           0.990730           0.990862           0.991142   \n",
       "95           0.990746           0.990879           0.991148   \n",
       "96           0.990737           0.990868           0.991151   \n",
       "97           0.990746           0.990879           0.991148   \n",
       "98           0.990728           0.990867           0.991144   \n",
       "99           0.990746           0.990879           0.991148   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.977626         0.975778        0.001008              100  \n",
       "1            0.989937         0.989361        0.000328               91  \n",
       "2            0.981275         0.979857        0.000785               99  \n",
       "3            0.990014         0.989474        0.000312               90  \n",
       "4            0.982692         0.981535        0.000645               98  \n",
       "5            0.990064         0.989549        0.000303               89  \n",
       "6            0.984076         0.982909        0.000665               97  \n",
       "7            0.990105         0.989612        0.000295               88  \n",
       "8            0.985016         0.984008        0.000576               96  \n",
       "9            0.990144         0.989670        0.000288               86  \n",
       "10           0.987198         0.986326        0.000497               95  \n",
       "11           0.990205         0.989736        0.000285               85  \n",
       "12           0.988656         0.988001        0.000383               94  \n",
       "13           0.990292         0.989833        0.000281               84  \n",
       "14           0.989393         0.988867        0.000317               93  \n",
       "15           0.990407         0.989959        0.000278               82  \n",
       "16           0.989816         0.989356        0.000283               92  \n",
       "17           0.990575         0.990132        0.000273               81  \n",
       "18           0.990096         0.989665        0.000269               87  \n",
       "19           0.990740         0.990308        0.000269               79  \n",
       "20           0.990277         0.989849        0.000268               83  \n",
       "21           0.990907         0.990486        0.000261               78  \n",
       "22           0.990611         0.990191        0.000272               80  \n",
       "23           0.991045         0.990637        0.000255               76  \n",
       "24           0.990947         0.990538        0.000263               77  \n",
       "25           0.991156         0.990758        0.000250               74  \n",
       "26           0.991127         0.990728        0.000255               75  \n",
       "27           0.991243         0.990852        0.000245               72  \n",
       "28           0.991220         0.990834        0.000242               73  \n",
       "29           0.991317         0.990922        0.000244               70  \n",
       "..                ...              ...             ...              ...  \n",
       "70           0.991429         0.991036        0.000240               43  \n",
       "71           0.991439         0.991044        0.000239               15  \n",
       "72           0.991424         0.991036        0.000239               45  \n",
       "73           0.991439         0.991044        0.000239               16  \n",
       "74           0.991428         0.991038        0.000236               33  \n",
       "75           0.991439         0.991044        0.000239               14  \n",
       "76           0.991427         0.991035        0.000237               46  \n",
       "77           0.991439         0.991044        0.000239               12  \n",
       "78           0.991430         0.991040        0.000237               31  \n",
       "79           0.991439         0.991044        0.000239               10  \n",
       "80           0.991427         0.991037        0.000239               39  \n",
       "81           0.991439         0.991044        0.000239               11  \n",
       "82           0.991434         0.991037        0.000240               37  \n",
       "83           0.991439         0.991044        0.000239                5  \n",
       "84           0.991424         0.991034        0.000240               50  \n",
       "85           0.991439         0.991044        0.000239                2  \n",
       "86           0.991424         0.991035        0.000238               47  \n",
       "87           0.991439         0.991044        0.000239                8  \n",
       "88           0.991429         0.991037        0.000240               41  \n",
       "89           0.991439         0.991044        0.000239                3  \n",
       "90           0.991421         0.991034        0.000237               52  \n",
       "91           0.991439         0.991044        0.000239                1  \n",
       "92           0.991432         0.991038        0.000241               34  \n",
       "93           0.991439         0.991044        0.000239                7  \n",
       "94           0.991434         0.991035        0.000242               48  \n",
       "95           0.991439         0.991044        0.000239                9  \n",
       "96           0.991444         0.991042        0.000244               28  \n",
       "97           0.991439         0.991044        0.000239                4  \n",
       "98           0.991430         0.991034        0.000241               53  \n",
       "99           0.991439         0.991044        0.000239                6  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation results\n",
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "#fit the default parameter\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of test data of default model:    \t 0.89\n"
     ]
    }
   ],
   "source": [
    "# Let's check the evaluation metrics of our default model\n",
    "y_pred = dt.predict(X_test)\n",
    "# check area under curve\n",
    "y_pred_prob = dt.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC of test data of default model:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7800 candidates, totalling 39000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 34.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 56.5min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-9e1c323a6398>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# fit tree on balanced training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    552\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "# parameters to build the model on\n",
    "params = {\"criterion\": ['gini', 'entropy'],'max_depth': range(1, 40),'min_samples_leaf': range(5, 200, 20),'min_samples_split': range(5, 200, 20),}\n",
    "\n",
    "\n",
    "# fit tree on balanced training data\n",
    "clf= GridSearchCV(estimator=dtree, cv=skf, param_grid=params, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best hyperparameters\n",
    "print(\"Best AUC: \", clf.best_score_)\n",
    "print(\"Best hyperparameters: \", clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate on test data \n",
    "from sklearn.metrics import roc_auc_score\n",
    "# predict  on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "# check area under curve\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "print(\"AUC of test data:    \\t\", round(roc_auc_score(y_test, y_pred_prob),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly explore other algorithms by building models like:\n",
    "- KNN\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceed with the model which shows the best result \n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the important features of the best model to understand the dataset\n",
    "- This will not give much explanation on the already transformed dataset\n",
    "- But it will help us in understanding if the dataset is not PCA transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building with balancing Classes\n",
    "\n",
    "##### Perform class balancing with :\n",
    "- Random Oversampling\n",
    "- SMOTE\n",
    "- ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "- Build different models on the balanced dataset and see the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model #import the package\n",
    "\n",
    "num_C = ______  #--> list of values\n",
    "cv_num =   #--> list of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### perfom cross validation on the X_train & y_train to create:\n",
    "- X_train_cv\n",
    "- X_test_cv \n",
    "- y_train_cv\n",
    "- y_test_cv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imblearn import over_sampling #- import the packages\n",
    "\n",
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using Random Oversampling\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarly explore other algorithms on balanced dataset by building models like:\n",
    "- KNN\n",
    "- SVM\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "sm = over_sampling.SMOTE(random_state=0)\n",
    "X_train_smote, y_train_smote = sm.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from SMOTE are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from SMOTE, we do\n",
    "X_train_smote_1 = X_train_smote[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial SMOTE Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using SMOTE\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build models on other algorithms to see the better performing on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the class distribution after applying ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from imblearn import over_sampling\n",
    "\n",
    "ada = over_sampling.ADASYN(random_state=0)\n",
    "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)\n",
    "# Artificial minority samples and corresponding minority labels from ADASYN are appended\n",
    "# below X_train and y_train respectively\n",
    "# So to exclusively get the artificial minority samples from ADASYN, we do\n",
    "X_train_adasyn_1 = X_train_adasyn[X_train.shape[0]:]\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_adasyn_1[:X_train_1.shape[0], 0], X_train_adasyn_1[:X_train_1.shape[0], 1],\n",
    "            label='Artificial ADASYN Class-1 Examples')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform cross validation & then balance classes on X_train_cv & y_train_cv using ADASYN\n",
    "\n",
    "#perform hyperparameter tuning\n",
    "\n",
    "#print the evaluation result by choosing a evaluation metric\n",
    "\n",
    "#print the optimum value of hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build models on other algorithms to see the better performing on ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the oversampling method which shows the best result on a model\n",
    "- Apply the best hyperparameter on the model\n",
    "- Predict on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform the best oversampling method on X_train & y_train\n",
    "\n",
    "clf = ___  #initialise the model with optimum hyperparameters\n",
    "clf.fit( ) # fit on the balanced dataset\n",
    "print() --> #print the evaluation score on the X_test by choosing the best evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the important features of the best model to understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp = []\n",
    "for i in clf.feature_importances_:\n",
    "    var_imp.append(i)\n",
    "print('Top var =', var_imp.index(np.sort(clf.feature_importances_)[-1])+1)\n",
    "print('2nd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-2])+1)\n",
    "print('3rd Top var =', var_imp.index(np.sort(clf.feature_importances_)[-3])+1)\n",
    "\n",
    "# Variable on Index-13 and Index-9 seems to be the top 2 variables\n",
    "top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-1])\n",
    "second_top_var_index = var_imp.index(np.sort(clf.feature_importances_)[-2])\n",
    "\n",
    "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
    "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
    "\n",
    "np.random.shuffle(X_train_0)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [20, 20]\n",
    "\n",
    "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
    "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
    "            label='Actual Class-0 Examples')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Print the FPR,TPR & select the best threshold from the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train auc =', metrics.roc_auc_score(_________)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(_________)\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
